import os
import time
import torch
import torch.optim as optim
from model import get_model
from data import load_data
import torch.nn.functional as F

def train(model, train_loader, optimizer, epoch, device = 'cuda'):
    model.train()                                        
    for batch_idx, (images, targets) in enumerate(train_loader):
        # data, target ê°’ DEVICEì— í• ë‹¹
        images = list(image.to(device) for image in images)
        targets = [{k: v.to(device) for k, v in t.items()} for t in targets]  

        optimizer.zero_grad()                 # optimizer gradient ê°’ ì´ˆê¸°í™”
        losses = model(images, targets)       # calculate loss

        loss = losses['loss_keypoint']        # keypoint loss
        loss.backward()                       # loss back propagation
        optimizer.step()                      # parameter update

        if (batch_idx+1) % 200 == 0:
            print(f'| epoch: {epoch} | batch: {batch_idx+1}/{len(train_loader)}')

def evaluate(model, test_loader, device = 'cuda'):
    model.train()      
    test_loss = 0      # test_loss ì´ˆê¸°í™”
    
    with torch.no_grad(): 
        for images, targets in test_loader:
            # data, target ê°’ DEVICEì— í• ë‹¹
            images = list(image.to(device) for image in images)
            targets = [{k: v.to(device) for k, v in t.items()} for t in targets]  

            losses = model(images, targets)                       # validation loss
            test_loss += float(losses['loss_keypoint'])           # sum of all loss 
    
    test_loss /= len(test_loader.dataset)                         # í‰ê·  loss
    return test_loss

def train_model(train_loader, val_loader, num_epochs = 30, device= 'cuda'):
    model_path = '/content/drive/MyDrive/models/RCNN.pt'
    
    # ê¸°ì¡´ ëª¨ë¸ì´ ìˆìœ¼ë©´ ë¡œë“œ, ì—†ìœ¼ë©´ ìƒˆ ëª¨ë¸ ìƒì„±
    if os.path.exists(model_path):
        print("âœ… ê¸°ì¡´ ëª¨ë¸ì„ ë¶ˆëŸ¬ì˜µë‹ˆë‹¤...")
        model = torch.load(model_path, map_location=device)
    else:
        print("ğŸ†• ìƒˆ ëª¨ë¸ì„ ìƒì„±í•©ë‹ˆë‹¤...")
        model = get_model()
    # model = get_model()
    
    model.to(device)
    
    best_loss = 999999  # initialize best loss
    optimizer = optim.SGD(model.parameters(), lr=1e-4, momentum=0.9, weight_decay=5e-4)

    for epoch in range(1, num_epochs+1):
        since = time.time()
        train(model, train_loader, optimizer, epoch, device)
        train_loss = evaluate(model, train_loader)
        val_loss = evaluate(model, val_loader)

        if val_loss <= best_loss:   # update best loss
          best_loss = val_loss
          torch.save(model, model_path)
          # torch.save(model, '../models/RCNN_ep'+str(epoch)+'_'+str(best_loss)+'.pt')
          print('Best Model Saved, Loss: ', val_loss)
        
        time_elapsed = time.time()-since
        print()
        print('---------------------- epoch {} ------------------------'.format(epoch))
        print('Train Keypoint Loss: {:.4f}, Val Keypoint Loss: {:.4f}'.format(train_loss, val_loss))   
        print('Completed in {:.0f}m {:.0f}s'.format(time_elapsed//60, time_elapsed%60))
        print()


def extract_confidence_scores(outputs):
    """ ëª¨ë¸ì˜ ì¶œë ¥ì—ì„œ confidence scoreë¥¼ ì¶”ì¶œí•˜ëŠ” í•¨ìˆ˜ """
    confidence_scores = []
    
    for output in outputs:
        if 'scores' in output:
            confidence_scores.append(output['scores'].cpu().numpy())  # scores ë¦¬ìŠ¤íŠ¸ ì €ì¥
        else:
            confidence_scores.append([])  # scoresê°€ ì—†ì„ ê²½ìš° ë¹ˆ ë¦¬ìŠ¤íŠ¸ ì¶”ê°€
    
    return confidence_scores


def evaluate_with_confidence(model, test_loader, device='cuda', output_json='confidence_scores.json'):
    """ ëª¨ë¸ í‰ê°€ ë° confidence score ì¶”ì¶œ í›„ JSONìœ¼ë¡œ ì €ì¥ """
    model.eval()  # í‰ê°€ ëª¨ë“œ
    confidence_results = []

    with torch.no_grad():
        for batch_idx, (images, targets) in enumerate(test_loader):
            images = [image.to(device) for image in images]
            targets = [{k: v.to(device) for k, v in t.items()} for t in targets]  

            outputs = model(images)  # ëª¨ë¸ ì˜ˆì¸¡ ê²°ê³¼
            
            confidence_scores = extract_confidence_scores(outputs)  # ìˆ˜ì •ëœ í•¨ìˆ˜ ì‚¬ìš©
            for idx, score in enumerate(confidence_scores):
                confidence_results.append({
                    "labels": targets[idx]["labels"].item(),
                    "confidence_score": score.tolist()  # numpy ë°°ì—´ì„ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜
                })

    # JSON íŒŒì¼ë¡œ ì €ì¥
    with open(output_json, "w") as f:
        json.dump(confidence_results, f, indent=4)

    print(f"âœ… Confidence scores saved to {output_json}")


def get_confidence():
    """ ê¸°ì¡´ ëª¨ë¸ì„ ë¡œë“œí•˜ê³  confidence scoreë¥¼ ê³„ì‚°í•˜ëŠ” í•¨ìˆ˜ """
    DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'

    # ë°ì´í„° ë¡œë“œ
    train_img_path = '../images/images_1'
    train_key_path = '/content/drive/MyDrive/annotations_1.csv'
    _, valid_loader = load_data(train_img_path, train_key_path)  # ê²€ì¦ ë°ì´í„° ë¡œë“œ

    # ê¸°ì¡´ ëª¨ë¸ ë¡œë“œ
    model_path = '/content/drive/MyDrive/models/RCNN.pt'
    if os.path.exists(model_path):
        print("âœ… ê¸°ì¡´ ëª¨ë¸ì„ ë¶ˆëŸ¬ì˜µë‹ˆë‹¤...")
        model = torch.load(model_path, map_location=DEVICE)
    else:
        print("ğŸ†• ìƒˆ ëª¨ë¸ì„ ìƒì„±í•©ë‹ˆë‹¤...")
        model = get_model()

    model.to(DEVICE)

    # Confidence score ì¶”ì¶œ ë° ì €ì¥
    evaluate_with_confidence(model, valid_loader, device=DEVICE)


def main():
    path = os.path.dirname(os.path.abspath(__file__))
    os.chdir(path)
    
    DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'

    train_img_path = '../images/images_1'
    train_key_path = '/content/drive/MyDrive/annotations_1.csv'

    train_loader, valid_loader = load_data(train_img_path, train_key_path)
    train_model(train_loader, valid_loader, num_epochs = 10, device = DEVICE) 
    '''
    default: epoch - 30, 
             device - cuda
    '''
if __name__=="__main__":
    # get_confidence()  # ê°’ ì¶”ì¶œ
    main()  # í›ˆë ¨
